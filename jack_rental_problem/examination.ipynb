{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_request_lambda_1 = 3\n",
    "expected_request_lambda_2 = 4\n",
    "\n",
    "expected_return_lambda_1 = 3 \n",
    "expected_return_lambda_2 = 2\n",
    "\n",
    "# -> at location 1, all cars rented are returned\n",
    "# -> at location 2, only half the cars rented are expected to be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location 1 actually has 3 rental requests and receives 3 cars that the customers returns || 0 car/s gained\n",
      "Location 2 actually has 3 rental requests and receives 0 cars that the customers returns || -3 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 4 rental requests and receives 3 cars that the customers returns || -1 car/s gained\n",
      "Location 2 actually has 3 rental requests and receives 0 cars that the customers returns || -3 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 6 rental requests and receives 2 cars that the customers returns || -4 car/s gained\n",
      "Location 2 actually has 3 rental requests and receives 3 cars that the customers returns || 0 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 1 rental requests and receives 3 cars that the customers returns || 2 car/s gained\n",
      "Location 2 actually has 5 rental requests and receives 0 cars that the customers returns || -5 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 4 rental requests and receives 5 cars that the customers returns || 1 car/s gained\n",
      "Location 2 actually has 4 rental requests and receives 4 cars that the customers returns || 0 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 1 rental requests and receives 1 cars that the customers returns || 0 car/s gained\n",
      "Location 2 actually has 4 rental requests and receives 1 cars that the customers returns || -3 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 5 rental requests and receives 1 cars that the customers returns || -4 car/s gained\n",
      "Location 2 actually has 3 rental requests and receives 3 cars that the customers returns || 0 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 4 rental requests and receives 3 cars that the customers returns || -1 car/s gained\n",
      "Location 2 actually has 5 rental requests and receives 4 cars that the customers returns || -1 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 4 rental requests and receives 3 cars that the customers returns || -1 car/s gained\n",
      "Location 2 actually has 4 rental requests and receives 1 cars that the customers returns || -3 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 0 rental requests and receives 4 cars that the customers returns || 4 car/s gained\n",
      "Location 2 actually has 2 rental requests and receives 8 cars that the customers returns || 6 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 5 rental requests and receives 2 cars that the customers returns || -3 car/s gained\n",
      "Location 2 actually has 3 rental requests and receives 4 cars that the customers returns || 1 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 4 rental requests and receives 2 cars that the customers returns || -2 car/s gained\n",
      "Location 2 actually has 6 rental requests and receives 1 cars that the customers returns || -5 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 2 rental requests and receives 7 cars that the customers returns || 5 car/s gained\n",
      "Location 2 actually has 1 rental requests and receives 2 cars that the customers returns || 1 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 5 rental requests and receives 7 cars that the customers returns || 2 car/s gained\n",
      "Location 2 actually has 6 rental requests and receives 0 cars that the customers returns || -6 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 5 rental requests and receives 2 cars that the customers returns || -3 car/s gained\n",
      "Location 2 actually has 3 rental requests and receives 0 cars that the customers returns || -3 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 5 rental requests and receives 3 cars that the customers returns || -2 car/s gained\n",
      "Location 2 actually has 3 rental requests and receives 1 cars that the customers returns || -2 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 2 rental requests and receives 5 cars that the customers returns || 3 car/s gained\n",
      "Location 2 actually has 3 rental requests and receives 2 cars that the customers returns || -1 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 3 rental requests and receives 3 cars that the customers returns || 0 car/s gained\n",
      "Location 2 actually has 2 rental requests and receives 2 cars that the customers returns || 0 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 3 rental requests and receives 3 cars that the customers returns || 0 car/s gained\n",
      "Location 2 actually has 1 rental requests and receives 5 cars that the customers returns || 4 car/s gained\n",
      "------------------------------------\n",
      "Location 1 actually has 3 rental requests and receives 2 cars that the customers returns || -1 car/s gained\n",
      "Location 2 actually has 6 rental requests and receives 1 cars that the customers returns || -5 car/s gained\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(days): \n",
    "    request1 = np.random.poisson(lam=expected_request_lambda_1)\n",
    "    request2 = np.random.poisson(lam=expected_request_lambda_2)\n",
    "\n",
    "    return1 = np.random.poisson(lam=expected_return_lambda_1)\n",
    "    return2 = np.random.poisson(lam=expected_return_lambda_2)\n",
    "\n",
    "    print(f\"Location 1 actually has {request1} rental requests and receives {return1} cars that the customers returns || {return1 - request1} car/s gained\")\n",
    "    print(f\"Location 2 actually has {request2} rental requests and receives {return2} cars that the customers returns || {return2 - request2} car/s gained\")\n",
    "\n",
    "    print(f\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4284856390692304"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(3, 3) \n",
    "a[(1, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent: \n",
    "    def __init__(self, cars1, cars2, cars_max: int, actions: list, starting_policy: list, states: list, rewards: list, theta: float, gamma: float): \n",
    "        # numbers of cars\n",
    "        self.cars1 = cars1 \n",
    "        self.cars2 = cars2\n",
    "        self.cars_max = cars_max\n",
    "\n",
    "        # variables for reinforcement learing\n",
    "\n",
    "        # policy contains index into the action array \n",
    "        self.policy = np.array(starting_policy) if type(starting_policy) != np.ndarray else starting_policy\n",
    "\n",
    "        # contains the actual value of increasing / decreasing the cars of the 2 locations \n",
    "        self.actions = np.array(actions) if type(actions) != np.ndarray else actions\n",
    "\n",
    "        # each state represents the number of cars in both locations\n",
    "        self.states = np.array(states) if type(states) != np.ndarray else states \n",
    "\n",
    "        # type of rewards available\n",
    "        self.rewards = rewards\n",
    "\n",
    "        self.theta = theta \n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.state_policy_values = np.zeros_like(self.states) \n",
    "\n",
    "        # the available states are the starting number of cars of each location to moving all cars from 1 place to another \n",
    "\n",
    "    def get_reward(self, reward_index, number_of_cars: int): \n",
    "        return self.rewards[reward_index] * number_of_cars\n",
    "\n",
    "    def p(self, s, action_index: tuple, next_day_rental_request_1: int, next_day_rental_request_2: int) -> tuple:\n",
    "        # do not include return because returns are only effective till the next day and is therefore added to the number of cars at each location at the end of the loop\n",
    "\n",
    "        # the probability of getting to the next state is 1 -> return next state\n",
    "\n",
    "        # what if the next day request is the actual request, and we assume that we actually know the environment and how it works ? \n",
    "\n",
    "        # from the current state and selecting the action `action_index`, how does it go? \n",
    "        # cars1 = self.cars1 + self.actions[action_index]\n",
    "        # cars2 = self.cars2 - self.actions[action_index]\n",
    "\n",
    "        cars1 = s[0]\n",
    "        cars2 = s[1]\n",
    "\n",
    "        number_of_cars_moved = self.actions[action_index]\n",
    "\n",
    "        if cars1 < np.abs(number_of_cars_moved) or cars2 < np.abs(number_of_cars_moved): \n",
    "            return None\n",
    "\n",
    "        cars1 +=  number_of_cars_moved\n",
    "        cars2 +=  number_of_cars_moved\n",
    "        \n",
    "        cost = self.get_reward(1, number_of_cars=np.abs(self.actions[action_index]))\n",
    "\n",
    "        final_reward = np.float32(0)\n",
    "\n",
    "        reward1 = self.get_reward(0, min(next_day_rental_request_1, cars1)) # if request > cars -> rent all cars. else, rent 'request' numbers of cars\n",
    "        reward2 = self.get_reward(0, min(next_day_rental_request_2, cars2)) # if request > cars -> rent all cars. else, rent 'request' numbers of cars\n",
    "\n",
    "        final_reward += reward1\n",
    "        final_reward += reward2\n",
    "        final_reward += cost\n",
    "\n",
    "        return final_reward, (cars1 - 1, cars2 - 1) \n",
    "\n",
    "    def get_action_from_policy(self, s: tuple) -> tuple: \n",
    "        \"\"\"\n",
    "        -> return the index into the action array \n",
    "        \"\"\"\n",
    "        return self.policy[s] \n",
    "\n",
    "    def policy_evaluation(self, next_day_rental_request_1, next_day_rental_request_2) -> None: \n",
    "        while True: \n",
    "            delta = np.float32(0)\n",
    "\n",
    "            # loop through each state\n",
    "            for i in range(self.state_policy_values.shape[0]): \n",
    "                for j in range(self.state_policy_values.shape[1]): \n",
    "                    s = (i, j)\n",
    "                    v = self.state_policy_values[s]\n",
    "\n",
    "                    # get action index from policy \n",
    "                    action_index = self.get_action_from_policy(s)\n",
    "\n",
    "                    # get reward and next state\n",
    "                    reward, next_state = self.p(s, action_index=action_index, next_day_rental_request_1=next_day_rental_request_1, next_day_rental_request_2=next_day_rental_request_2)\n",
    "\n",
    "                    # update current value function of current policy \n",
    "                    self.state_policy_values[s] = reward + self.gamma * self.state_policy_values[next_state]\n",
    "\n",
    "                    delta = max(delta, np.abs(v - self.state_policy_values[s]))\n",
    "\n",
    "            if delta < self.theta: \n",
    "                break \n",
    "\n",
    "        return \n",
    "\n",
    "    def policy_improvement_step(self, next_day_rental_request_1, next_day_rental_request_2) -> bool: \n",
    "        \"\"\"\n",
    "        -> returns True if the best policy is found, returns false if the policy is not found\n",
    "        \"\"\"\n",
    "        for i in range(self.state_policy_values.shape[0]): \n",
    "            for j in range(self.state_policy_values.shape[1]): \n",
    "                s = (i, j)\n",
    "                a = self.get_action_from_policy(s)\n",
    "\n",
    "                # getting the best action for the current state based on the value function \n",
    "                best_action_index = np.zeros(2) \n",
    "                best_action_value = np.float32(0)\n",
    "\n",
    "                for x in range(self.actions.shape[0]): \n",
    "                    for y in range(self.actions.shape[1]): \n",
    "                        action_index = (x, y) \n",
    "                        reward, next_state = self.p(s=s, action_index=action_index, next_day_rental_request_1=next_day_rental_request_1, next_day_rental_request_2=next_day_rental_request_2)\n",
    "\n",
    "                        current_action_value = reward + self.state_policy_values[next_state]\n",
    "\n",
    "                        if current_action_value > best_action_value: \n",
    "                            best_action_value = current_action_value\n",
    "                            best_action_index = action_index\n",
    "\n",
    "                if a != best_action_index: \n",
    "                    return False\n",
    "                else: \n",
    "                    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(cars1=1, cars2=1, cars_max=3, actions=np.arange(0, 4, 1), starting_policy=np.zeros((3, 3)), states=np.zeros((3, 3)), rewards=[0, 10, -2], theta=1e-3, gamma=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
