{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tqdm import tqdm \n",
    "from environment import Enviroment\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_function = np.load(\"./theoretical/value_function.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.61344469,  8.9999211 , 11.75661048, 13.83162614],\n",
       "       [ 8.99481133, 12.38128889, 15.13797997, 17.21299667],\n",
       "       [11.8889956 , 15.27547344, 18.03216484, 20.10718163],\n",
       "       [14.03204792, 17.41852942, 20.17522531, 22.25024349]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.load(\"./theoretical/actions.npy\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_history = np.load(\"./theoretical/history.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]]\n",
      "[[[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]]\n"
     ]
    }
   ],
   "source": [
    "for policy in policy_history: \n",
    "    print(policy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_policy = policy_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]]\n"
     ]
    }
   ],
   "source": [
    "print(optimal_policy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the efficiency of each policy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester: \n",
    "    def __init__(self, cars1, cars2, cars_max, policy, actions): \n",
    "        self.cars1 = cars1\n",
    "        self.cars2 = cars2 \n",
    "        self.cars_max = cars_max\n",
    "        self.policy = policy\n",
    "        self.actions = actions\n",
    "\n",
    "    def update_cars(self, new_car_1, new_car_2): \n",
    "        self.cars1 = new_car_1\n",
    "        self.cars2 = new_car_2\n",
    "\n",
    "    def get_cars(self): \n",
    "        return (self.cars1, self.cars2)\n",
    "\n",
    "    def get_action_index(self, s): \n",
    "        action_index = self.policy[s]\n",
    "        action_index = tuple(action_index)\n",
    "        return action_index\n",
    "\n",
    "    def get_action(self, action_index): \n",
    "        return self.actions[action_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = np.load(\"./theoretical/constants.npy\")\n",
    "number_of_days = 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, -2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = np.load(\"./theoretical/rewards.npy\")\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 0, -1, -2, -3]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_number_of_cars, expected_request_lambda_1, expected_request_lambda_2, expected_return_lambda_1, expected_return_lambda_2 = constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Enviroment(expected_request_lambda_1=expected_request_lambda_1, expected_request_lambda_2=expected_request_lambda_2,\n",
    "                             expected_return_lambda_1=expected_return_lambda_1, expected_return_lambda_2=expected_return_lambda_2, agent=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars1 = 2\n",
    "cars2 = 1\n",
    "\n",
    "tester_list = [] \n",
    "np.random.seed(42) \n",
    "\n",
    "for policy in policy_history: \n",
    "    tester = Tester(cars1, cars2, max_number_of_cars, policy=policy, actions=actions)\n",
    "\n",
    "    tester_list.append(tester) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating sales for tester 0: 100%|██████████| 2000000/2000000 [00:14<00:00, 133464.51it/s]\n",
      "Simulating sales for tester 1: 100%|██████████| 2000000/2000000 [00:14<00:00, 134608.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best policy from simulation: 0 || best policy from agent: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reward_list = []\n",
    "for i, tester in enumerate(tester_list): \n",
    "    current_reward = 0.0\n",
    "\n",
    "    for d in tqdm(range(number_of_days), desc=f\"Simulating sales for tester {i}\"): \n",
    "        rental_request_1, rental_request_2 = environment.get_rental_requests()\n",
    "        customer_return_1, customer_return_2 = environment.get_customer_returns()\n",
    "\n",
    "        # current number of cars \n",
    "        cars1, cars2 = tester.get_cars()\n",
    "\n",
    "        # renting out the cars\n",
    "        cars_rented_1 = min(cars1, rental_request_1)\n",
    "        cars_rented_2 = min(cars2, rental_request_2)\n",
    "\n",
    "        # calculate reward for cars rented\n",
    "        current_reward += rewards[0] * cars_rented_1\n",
    "        current_reward += rewards[0] * cars_rented_2\n",
    "\n",
    "        # calculate new car number for tomorrow\n",
    "        cars1 -= cars_rented_1\n",
    "        cars2 -= cars_rented_2\n",
    "\n",
    "        cars1 += customer_return_1\n",
    "        cars2 += customer_return_2\n",
    "\n",
    "        # set cars to not exceed limit\n",
    "        cars1 = min(cars1, tester.cars_max)\n",
    "        cars2 = min(cars2, tester.cars_max)\n",
    "\n",
    "        # select the best action based on the current policy and current state\n",
    "        action_index = tester.get_action_index((cars1, cars2))\n",
    "        number_of_cars_moved = tester.get_action(action_index) \n",
    "\n",
    "        # cost of moving cars\n",
    "        cost = rewards[1] * np.abs(number_of_cars_moved)\n",
    "        current_reward += cost\n",
    "\n",
    "        # update the cars to the number of cars moved\n",
    "        cars1 += number_of_cars_moved\n",
    "        cars2 -= number_of_cars_moved\n",
    "\n",
    "        # set cars to not exceed the limit \n",
    "        cars1 = min(cars1, tester.cars_max)\n",
    "        cars2 = min(cars2, tester.cars_max)\n",
    "\n",
    "        # update new car numbers\n",
    "        tester.update_cars(cars1, cars2)\n",
    "    \n",
    "    reward_list.append(current_reward)\n",
    "\n",
    "reward_list = np.array(reward_list) \n",
    "best_policy = np.argmax(reward_list) \n",
    "print(f\"best policy from simulation: {best_policy} || best policy from agent: {len(policy_history) - 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([74160580., 74143980.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between best in simulation and optimal policy: 16600.0\n"
     ]
    }
   ],
   "source": [
    "difference = reward_list[best_policy] - reward_list[-1]\n",
    "print(f\"Difference between best in simulation and optimal policy: {difference}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize policies as a contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception contour\n",
      "exception contour\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "x = np.arange(0, max_number_of_cars + 1)\n",
    "y = np.arange(0, max_number_of_cars + 1)\n",
    "\n",
    "for policy_index, policy in enumerate(policy_history): \n",
    "    z = np.zeros_like(policy) \n",
    "\n",
    "    for i in range(policy.shape[0]): \n",
    "        for j in range(policy.shape[1]): \n",
    "            state = (i, j) \n",
    "            action_index = policy[state] \n",
    "            action = actions[action_index[0], action_index[1]]\n",
    "\n",
    "            z[state] = action\n",
    "\n",
    "    try: \n",
    "        axes[policy_index].contour([x, y], z)\n",
    "    except Exception as e: \n",
    "        axes[policy_index].contour([x, y], z, levels=[0])\n",
    "        print(\"exception contour\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
