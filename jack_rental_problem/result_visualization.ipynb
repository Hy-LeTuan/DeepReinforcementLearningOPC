{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tqdm import tqdm \n",
    "from environment import Enviroment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_function = np.load(\"./value_function.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[470.00565273, 480.00565273, 490.00565273],\n",
       "       [480.00565273, 490.00565273, 500.00565273],\n",
       "       [480.00565273, 490.00565273, 500.00565273]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.load(\"./actions.npy\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_history = np.load(\"./history.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_policy = policy_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]]]\n"
     ]
    }
   ],
   "source": [
    "print(optimal_policy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the efficiency of each policy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester: \n",
    "    def __init__(self, cars1, cars2, cars_max, policy, actions): \n",
    "        self.cars1 = cars1\n",
    "        self.cars2 = cars2 \n",
    "        self.cars_max = cars_max\n",
    "        self.policy = policy\n",
    "        self.actions = actions\n",
    "\n",
    "    def update_cars(self, new_car_1, new_car_2): \n",
    "        self.cars1 = new_car_1\n",
    "        self.cars2 = new_car_2\n",
    "\n",
    "    def get_cars(self): \n",
    "        return (self.cars1, self.cars2)\n",
    "\n",
    "    def get_action_index(self, s): \n",
    "        action_index = self.policy[s]\n",
    "        action_index = tuple(action_index)\n",
    "        return action_index\n",
    "\n",
    "    def get_action(self, action_index): \n",
    "        return self.actions[action_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = np.load(\"./constants.npy\")\n",
    "number_of_days = 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, -2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = np.load(\"./rewards.npy\")\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 0, -1, -2, -3]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_number_of_cars, expected_request_lambda_1, expected_request_lambda_2, expected_return_lambda_1, expected_return_lambda_2 = constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Enviroment(expected_request_lambda_1=expected_request_lambda_1, expected_request_lambda_2=expected_request_lambda_2,\n",
    "                             expected_return_lambda_1=expected_return_lambda_1, expected_return_lambda_2=expected_return_lambda_2, agent=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars1 = 2\n",
    "cars2 = 1\n",
    "\n",
    "tester_list = [] \n",
    "\n",
    "for policy in policy_history: \n",
    "    tester = Tester(cars1, cars2, max_number_of_cars, policy=policy, actions=actions)\n",
    "\n",
    "    tester_list.append(tester) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating sales for tester 0: 100%|██████████| 10000000/10000000 [01:11<00:00, 138929.24it/s]\n",
      "Simulating sales for tester 1: 100%|██████████| 10000000/10000000 [01:11<00:00, 139117.31it/s]\n",
      "Simulating sales for tester 2: 100%|██████████| 10000000/10000000 [01:12<00:00, 137457.68it/s]\n",
      "Simulating sales for tester 3: 100%|██████████| 10000000/10000000 [01:12<00:00, 138627.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best policy from simulation: 2 || best policy from agent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reward_list = []\n",
    "for i, tester in enumerate(tester_list): \n",
    "    current_reward = 0\n",
    "    for d in tqdm(range(number_of_days), desc=f\"Simulating sales for tester {i}\"): \n",
    "        rental_request_1, rental_request_2 = environment.get_rental_requests()\n",
    "        customer_return_1, customer_return_2 = environment.get_customer_returns()\n",
    "\n",
    "        # current number of cars \n",
    "        cars1, cars2 = tester.get_cars()\n",
    "\n",
    "        # renting out the cars\n",
    "        cars_rented_1 = min(cars1, rental_request_1)\n",
    "        cars_rented_2 = min(cars2, rental_request_2)\n",
    "\n",
    "        # calculate new car number for tomorrow\n",
    "        cars1 -= cars_rented_1\n",
    "        cars2 -= cars_rented_2\n",
    "\n",
    "        cars1 += customer_return_1\n",
    "        cars2 += customer_return_2\n",
    "\n",
    "        # set cars to not exceed limit\n",
    "        cars1 = min(cars1, tester.cars_max)\n",
    "        cars2 = min(cars2, tester.cars_max)\n",
    "\n",
    "        # calculate reward for cars rented\n",
    "        current_reward += rewards[0] * cars_rented_1\n",
    "        current_reward += rewards[0] * cars_rented_2\n",
    "\n",
    "        # select the best action based on the current policy and current state\n",
    "        action_index = tester.get_action_index((cars1 - 1, cars2 - 1))\n",
    "        number_of_cars_moved = tester.get_action(action_index) \n",
    "\n",
    "        if number_of_cars_moved != 0: \n",
    "            print(f\"number of cars moved: {number_of_cars_moved}\")\n",
    "\n",
    "        # cost of moving cars\n",
    "        cost = rewards[1] * np.abs(number_of_cars_moved)\n",
    "        current_reward += cost\n",
    "\n",
    "        # update the cars to the number of cars moved\n",
    "        cars1 += number_of_cars_moved\n",
    "        cars2 -= number_of_cars_moved\n",
    "\n",
    "        # set cars to not exceed the limit \n",
    "        cars1 = min(cars1, tester.cars_max)\n",
    "        cars2 = min(cars2, tester.cars_max)\n",
    "    \n",
    "    reward_list.append(current_reward)\n",
    "\n",
    "reward_list = np.array(reward_list) \n",
    "best_policy = np.argmax(reward_list) \n",
    "print(f\"best policy from simulation: {best_policy} || best policy from agent: {len(policy_history) - 1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
